## Основные моменты с учетом задания

### 1. Мультизональный кластер (3 зоны, 5 нод)

**Topology Spread Constraints:**
- Жесткое распределение по зонам (`topology.kubernetes.io/zone`):
  - `maxSkew: 1`
  - `whenUnsatisfiable: DoNotSchedule`
- Мягкое распределение по нодам (`kubernetes.io/hostname`) для равномерного распределения

**Pod Anti-Affinity:**
- Обязательное правило (`requiredDuringScheduling`) для распределения по разным зонам
- Предпочтительное правило (`preferredDuringScheduling`) для распределения по разным нодам

---

### 2. Инициализация приложения (5-10 сек)

**Readiness Probe:**
- `initialDelaySeconds: 15` (больше времени на инициализацию)
- `periodSeconds: 5`
- `failureThreshold: 3` (быстрое обнаружение проблем)

**Liveness Probe:**
- `initialDelaySeconds: 20` (чтобы не убивать поды при медленном старте)
- `periodSeconds: 10`
- `failureThreshold: 3`

---

### 3. Нагрузка (4 пода справляются с пиком, ночью — мало запросов)

**HPA (Horizontal Pod Autoscaler):**
- `Min replicas: 2` (ночью, чтобы экономить ресурсы)
- `Max replicas: 5` (пиковая нагрузка + 1 под для отказоустойчивости)

**Метрики масштабирования:**
- CPU: `targetAverageUtilization: 70%` (агрессивнее, так как после старта потребление CPU падает)
- Memory: `targetAverageUtilization: 85%` (память стабильна, но лимит жесткий)
- RPS (если метрика есть): `averageValue: 1000`

**Политики масштабирования:**
- Scale Up: Быстро (30 сек стабилизации, до 100% за раз)
- Scale Down: Медленно (15 мин стабилизации, максимум 25% за раз)

---

### 4. Потребление CPU (первые запросы — высокие, потом ~0.1 CPU)

**Resources:**
- **Requests:**
  - CPU: `200m` (чтобы быстро стартовало)
  - Memory: `128Mi` (ровное потребление)
- **Limits:**
  - CPU: `1` (для пиковых нагрузок)
  - Memory: `256Mi` (запас на случай всплесков)

---

### 5. Отказоустойчивость

- **Replicas:** 5 (4 на нагрузку + 1 запасной)
- **PodDisruptionBudget (PDB):** `minAvailable: 50%` (гарантирует, что при обновлениях/сбоях останется минимум 2-3 пода)
- **Graceful Shutdown:**
  - `terminationGracePeriodSeconds: 60`
  - `preStop: sleep 20` (завершение активных соединений)

---

### 6. Экономия ресурсов

**Ночью:**
- HPA уменьшает до 2 подов (экономия CPU)
- Можно добавить CronHPA или KEDA для предсказуемого масштабирования по расписанию

**При низкой нагрузке:**
- Поды не уходят ниже `minReplicas: 2`, чтобы сохранить отказоустойчивость

---

## Итоговая конфигурация

**Для отказоустойчивости:**
- Распределение по зонам + Anti-Affinity
- 5 реплик (4 на нагрузку + 1 запасной)
- PDB на 50%

**Для экономии ресурсов:**
- HPA (2-5 подов, медленный Scale Down)
- Заниженные requests (особенно CPU после старта)

**Для стабильности:**
- Надежные Readiness/Liveness Probes
- Graceful Shutdown

**Дополнительно (если ночью нагрузка очень низкая):**
- Включить вертикальное масштабирование (VPA) для уменьшения CPU requests (но осторожно, может влиять на старт)
- Использовать KEDA для масштабирования до 1 пода ночью (если допустимо кратковременное замедление ответов)

Такой подход обеспечит баланс между отказоустойчивостью и экономией ресурсов.
